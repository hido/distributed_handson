====================
 イントロダクション
====================

イントロでは、Jubatusと分散処理の関係と、機械学習の簡単な説明をを行います。
より詳しい機械学習の説明とJubatusの説明は、参考文献を参照してください。


Jubatusと分散
-------------------

Jubatusは、2011年秋に公開されてから二年半ほどになります。
Jubatusが開発した当初から目指していた世界は、
「さまざまな所で大量のデータが生成され続けている。これらのデータをリアルタイムに学習しながらリアルタイムに分析を行う」というものです。この世界を実現するために、「オンライン機械学習」を「分散処理」する、という仕組みを考えました。前回のハンズオンでは主に「オンライン機械学習」にフォーカスを当てた説明を行いました。
今回のハンズオンでは、「分散処理」にフォーカスをあてて説明します。

Jubatusは、そもそもなぜ分散するのでしょうか？
Jubatusは先に述べた通り、「さまざまな所で大量のデータが生成され続けている。これらのデータをリアルタイムに学習しながらリアルタイムに分析を行う」を実現します。
しかし一般的な話として、一台で処理できる単位時間あたりの処理量は限られているため、一台でリアルタイムに処理できるデータの量は限られています。
また、データは生成され続けているため、データを分析し続ける必要があります。そのため、分析しているノードで障害が発生したりしても正しく動作し続ける必要があります。
これらに対処するために、クラスタ構成を組んで、スループットを上げたり、冗長構成を取って、耐障害性を高めたりします。

しかし、機械学習や分散処理をよくご存知のかたは疑問に思うかもしれません。
これらノード間 or 機械学習の演算 の同期をどのように実現しているのだろう、と。

Jubatusは ``MIX`` という独自の仕組みを用いて、これらを解決しています。

MIXとはなにか
----------------------

Jubatusにおいてサーバ同士が、緩やかなモデルの共有を行う仕組みのことを ``MIX`` といいます。

本章ではこの「緩やかな」を知るために、0.4.0から利用できる ``jubaanomaly`` のアルゴリズムと、分散方式、及びそのMIXについて紹介します。


``jubaanomaly`` とは、外れ値検出を行うアルゴリズムを実装したサーバです。
外れ値検出は異常検知の一種に属するタスクで、与えられたデータセットの中で、その他大勢とは異なる少数のサンプルを外れ値として見つけるものです。
単純には、正常サンプルは小さい領域に固まって分布しているのに対し、外れ値（異常）サンプルはそこから離れた領域に単独で存在しています。
Jubatusで実装されている外れ値検出アルゴリズムはLocal Outlier Factor (LOF)と呼ばれるものです。
これは、サンプル間の距離をベースとした手法であり、実際に内部ではレコメンダまたは近傍探索の機能を用いています。
計算手法としては、まずサンプルペアに対してk-distとlocal reachability density (lrd)というメタデータを計算します。
それぞれ、k番目の近傍への距離と、k個の近傍への距離またはk-distの大きい方の平均値に対応しています。
lrdは、各サンプルの周辺のデータ密度の近似とも言えます。
最終的な異常度スコア（LOF値）はk個の近傍の平均lrd値と自身のlrd値の比で計算され、正常であれば1.0周辺、異常であればあるほど1.0よりも大きな値を取ります。
特徴としては、データ密度を考慮することで、単純に距離だけを用いて外れ値を検出した場合に局所的な密度の差の影響を受けてしまうことを防げる点があります。
各サンプルはEuclid LSHなどを用いたハッシュ値表現と、k-distおよびlrdのペアというメタデータで内部的に表現されており、新しいサンプルに対するLOF値もすぐに計算できるようになっています。

Jubatusは、クライアントコードから分散処理を意識させないようにするためにProxyというプロセスを用意しています。Proxyは当初、Zookeeperとのやりとりを代行するプロセスとして、Keeperという名前が付けられていましたが、Zookeeperとのやりとりだけではなく、分散処理そのものを代行して行う、プロキシプロセスであるということで、変更が加えられました。

JubatusのProxyはクライアントにたいして、Serverのように振る舞います。NAMEで指定された機械学習タスクごとにServerが登録されています。Proxyは、クライアントからのクエリを受けると、そのServerのリストから適切なサーバを適切なアルゴリズムを使って選び、クエリを代行します。
これにより、クライアントを使ってアプリケーションを開発する人は、裏で何台のサーバーが動作しているのか気にすることなくアプリケーションロジックの開発に専念できるようになります。
``jubaanomaly_proxy`` は、この振り分けロジックに ``ID`` をキーとするコンシステントハッシングを利用しています。
これにより台数を増やせば増やすほど、単位時間あたりの学習量と分析量をスケールアウトさせることが出来ます。

コンシステントハッシングを使ってデータを割り振って別々に学習しているので、このままでは、別のサーバで学習した結果、 ``jubaanomaly`` の場合は別サーバに存在するデータを利用することが出来ません。
そこで行うのが、MIXです。 外れ値検出におけるMIXとは、それぞれのデータサンプルに対応するハッシュ値のリストと、メタデータを共有することです。お互いに持っていないデータや古いデータを見つけて上書きするだけです。
``MIX`` は、指定した個数の学習、もしくは最後にMIXしてからの指定時間が経過したときに起こります。 つまりその間は クラスタ全体としてみると正しい結果が得られない可能性があります。
このような状況を「穏やかな」モデルの共有、と表現し、これらを実現する仕組みを ``MIX`` と読んでいます。

MIXはアルゴリズムごとに手法が異なります。そのため精度は、タスクの種類、MIXの頻度、データ入力のタイミングなどにより変化します。


.. note::

   jubaclassifierにおけるMIXは、MIXのタイミングとデータ入力のタイミングによって、入力されたデータが失われる（モデルに反映されない）ことがあります。

